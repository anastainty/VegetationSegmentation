import torch
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
from datetime import datetime

import config
from dataset import VegetationDataset
from model import UNet

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
MODEL_PATH = "unet_vegetation_model.pth"
CLASSES = ["–§–æ–Ω", "–ê—Å—Ñ–∞–ª—å—Ç", "–¢—Ä–∞–≤–∞", "–ö—É—Å—Ç—ã", "–õ–µ—Å"]


def evaluate_model():
    print(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {config.DEVICE}")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑: {config.IMAGE_PATH}")

    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    results_dir = os.path.join(base_dir, "data", "processed", "results", timestamp)
    os.makedirs(results_dir, exist_ok=True)
    print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: {results_dir}")

    if not os.path.exists(config.IMAGE_PATH) or not os.path.exists(config.MASK_PATH):
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö.")
        return

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    val_dataset = VegetationDataset(
        image_path=config.IMAGE_PATH,
        mask_path=config.MASK_PATH,
        dsm_path=config.DSM_PATH,
        transform=None
    )
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)

    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = UNet(n_channels=6, n_classes=5).to(config.DEVICE)

    if not os.path.exists(MODEL_PATH):
        alt_path = os.path.join("src", MODEL_PATH)
        current_model_path = alt_path if os.path.exists(alt_path) else None
    else:
        current_model_path = MODEL_PATH

    if not current_model_path:
        print(f"‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ {MODEL_PATH}.")
        return

    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –∏–∑: {current_model_path}")
    model.load_state_dict(torch.load(current_model_path, map_location=config.DEVICE))
    model.eval()

    all_preds = []
    all_targets = []

    # 4. –ü—Ä–æ–≥–æ–Ω –¥–∞–Ω–Ω—ã—Ö
    print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(val_loader)}")
    with torch.no_grad():
        for images, masks in tqdm(val_loader, desc="–°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏"):
            images = images.to(config.DEVICE)
            outputs = model(images)
            preds = torch.argmax(outputs, dim=1).cpu().numpy().flatten()
            targets = masks.cpu().numpy().flatten()
            all_preds.extend(preds)
            all_targets.extend(targets)

    # --- –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ù–ê–ß–ò–ù–ê–Æ–¢–°–Ø –ó–î–ï–°–¨ ---

    # 5. –°–Ω–∞—á–∞–ª–∞ —Å—á–∏—Ç–∞–µ–º –ú–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ (–Ω—É–∂–Ω–∞ –¥–ª—è IoU)
    print("\nüßÆ –†–∞—Å—á–µ—Ç –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ –∏ IoU...")
    cm = confusion_matrix(all_targets, all_preds)

    # –°—á–∏—Ç–∞–µ–º IoU –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    iou_scores = []
    for i in range(len(CLASSES)):
        if i < cm.shape[0] and i < cm.shape[1]:
            tp = cm[i, i]
            fp = cm[:, i].sum() - tp
            fn = cm[i, :].sum() - tp
            denominator = tp + fp + fn
            iou = tp / denominator if denominator > 0 else 0.0
            iou_scores.append(iou)
        else:
            iou_scores.append(0.0)

    mean_iou = np.mean(iou_scores)

    # 6. –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–µ–≥–æ IoU
    print("üìà –ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –æ—Ç—á–µ—Ç–∞...")
    report_dict = classification_report(all_targets, all_preds, target_names=CLASSES, output_dict=True, zero_division=0)
    df_report = pd.DataFrame(report_dict).transpose()

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É IoU
    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é –∫–æ–ª–æ–Ω–∫—É
    df_report['IoU'] = np.nan

    # –ó–∞–ø–æ–ª–Ω—è–µ–º IoU –ø–æ –∫–ª–∞—Å—Å–∞–º
    for i, class_name in enumerate(CLASSES):
        if class_name in df_report.index:
            df_report.loc[class_name, 'IoU'] = iou_scores[i]

    # –ó–∞–ø–æ–ª–Ω—è–µ–º Mean IoU –≤ —Å—Ç—Ä–æ–∫—É 'macro avg' (—Å—Ä–µ–¥–Ω–µ–µ)
    if 'macro avg' in df_report.index:
        df_report.loc['macro avg', 'IoU'] = mean_iou

    # –í—ã–≤–æ–¥ –∫—Ä–∞—Å–∏–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ –∫–æ–Ω—Å–æ–ª—å (–∑–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ –ø—Ä–æ—á–µ—Ä–∫–∏ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã –≤—ã–≤–æ–¥–∞, –Ω–æ –≤ CSV –æ—Å—Ç–∞–≤–∏–º —á–∏—Å–ª–∞)
    print("\n=== –ü–û–õ–ù–´–ô –û–¢–ß–ï–¢ (—Å IoU) ===")
    print(df_report)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV
    csv_path = os.path.join(results_dir, "accuracy_report.csv")
    df_report.to_csv(csv_path)
    print(f"üìÑ –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {csv_path}")

    # 7. –†–∏—Å—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ (–∫–∞—Ä—Ç–∏–Ω–∫–∞)
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    cm_normalized = np.nan_to_num(cm_normalized)

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm_normalized, annot=True, fmt=".2f", cmap="Blues",
                xticklabels=CLASSES, yticklabels=CLASSES)
    plt.title(f"Confusion Matrix (Mean IoU: {mean_iou:.4f})")
    plt.ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.tight_layout()

    plot_path = os.path.join(results_dir, "confusion_matrix.png")
    plt.savefig(plot_path, dpi=300)
    print(f"üñº –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {plot_path}")

    # 8. –ö—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç (–¥—É–±–ª–∏—Ä—É–µ–º IoU —Ç—É–¥–∞ —Ç–æ–∂–µ)
    with open(os.path.join(results_dir, "summary.txt"), "w") as f:
        f.write(f"Model: {current_model_path}\n")
        f.write(f"Date: {timestamp}\n")
        f.write(f"Mean IoU: {mean_iou:.4f}\n")
        f.write("-" * 20 + "\n")
        for i, score in enumerate(iou_scores):
            f.write(f"IoU {CLASSES[i]}: {score:.4f}\n")


if __name__ == "__main__":
    evaluate_model()