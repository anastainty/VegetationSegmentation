import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from tqdm import tqdm
import matplotlib.pyplot as plt
import os

import config
from dataset import VegetationDataset
from model import UNet


def train():
    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print("--- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---")

    # –í–∫–ª—é—á–∞–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é (–ø–æ–≤–æ—Ä–æ—Ç—ã, –æ—Ç—Ä–∞–∂–µ–Ω–∏—è)
    full_dataset = VegetationDataset(
        config.IMAGE_PATH,
        config.DSM_PATH,
        config.MASK_PATH,
        patch_size=config.PATCH_SIZE,
        augment=True
    )

    train_size = int(0.8 * len(full_dataset))
    val_size = len(full_dataset) - train_size

    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

    print(f"–í—Å–µ–≥–æ –ø–∞—Ç—á–µ–π: {len(full_dataset)}")
    print(f"–û–±—É—á–µ–Ω–∏–µ: {len(train_dataset)} | –í–∞–ª–∏–¥–∞—Ü–∏—è: {len(val_dataset)}")

    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)

    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    print(f"\n--- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (U-Net) –Ω–∞ {config.DEVICE} ---")
    model = UNet(n_channels=config.NUM_CHANNELS, n_classes=config.NUM_CLASSES)
    model = model.to(config.DEVICE)

    class_weights = torch.tensor([0.34, 1.36, 2.24, 3.88, 1.7]).to(config.DEVICE)

    criterion = nn.CrossEntropyLoss(weight=class_weights, ignore_index=0)

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (weight_decay)
    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-4)

    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ (—Å–Ω–∏–∂–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –≤—ã—à–ª–∏ –Ω–∞ –ø–ª–∞—Ç–æ)
    # verbose —É–¥–∞–ª–µ–Ω, —Ç–∞–∫ –∫–∞–∫ —É—Å—Ç–∞—Ä–µ–ª –≤ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö PyTorch
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)

    train_losses = []
    val_losses = []

    # --- –ù–ê–°–¢–†–û–ô–ö–ò EARLY STOPPING (–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞) ---
    best_val_loss = float('inf')
    patience_limit = 15  # –°–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö –∂–¥–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è, –ø—Ä–µ–∂–¥–µ —á–µ–º —Å–¥–∞—Ç—å—Å—è
    patience_counter = 0

    # 3. –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
    for epoch in range(config.NUM_EPOCHS):
        model.train()
        running_loss = 0.0

        loop = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{config.NUM_EPOCHS}")

        for images, masks in loop:
            images = images.to(config.DEVICE)
            masks = masks.to(config.DEVICE)

            optimizer.zero_grad()
            outputs = model(images)

            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            loop.set_postfix(loss=loss.item())

        epoch_loss = running_loss / len(train_loader)
        train_losses.append(epoch_loss)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for images, masks in val_loader:
                images = images.to(config.DEVICE)
                masks = masks.to(config.DEVICE)
                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)

        # –û–±–Ω–æ–≤–ª—è–µ–º LR –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        scheduler.step(avg_val_loss)

        # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—É—â–∏–π LR –≤—Ä—É—á–Ω—É—é
        current_lr = optimizer.param_groups[0]['lr']
        print(
            f"Epoch {epoch + 1} -> Train Loss: {epoch_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {current_lr:.6f}")

        # --- –õ–û–ì–ò–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø –ò –û–°–¢–ê–ù–û–í–ö–ò ---
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫, —Ç–∞–∫ –∫–∞–∫ –º—ã —É–ª—É—á—à–∏–ª–∏—Å—å
            torch.save(model.state_dict(), "unet_vegetation_model.pth")
            print("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (–ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)!")
        else:
            patience_counter += 1
            print(f"‚è≥ –ù–µ—Ç —É–ª—É—á—à–µ–Ω–∏–π {patience_counter}/{patience_limit} —ç–ø–æ—Ö.")

            if patience_counter >= patience_limit:
                print("\nüõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞: –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ—Å—Ç–∞–ª–∞ –æ–±—É—á–∞—Ç—å—Å—è.")
                break

    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    os.makedirs(config.PLOTS_DIR, exist_ok=True)
    plot_path = os.path.join(config.PLOTS_DIR, 'training_plot.png')

    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('–ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è')
    plt.xlabel('–≠–ø–æ—Ö–∏')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig(plot_path)
    plt.close()
    print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {plot_path}")


if __name__ == "__main__":
    train()